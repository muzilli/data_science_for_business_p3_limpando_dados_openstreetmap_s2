{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study\n",
    "\n",
    "### Mapa da Area a ser analisada\n",
    "\n",
    "\n",
    "Manhattan (8398124) in New York Citt, NY, United States of America\n",
    "\n",
    "- [https://www.openstreetmap.org/relation/8398124](https://www.openstreetmap.org/relation/8398124)\n",
    "\n",
    "Query realizada no site abaixo para buscar os dados do quadrante que será utilizado para análise:\n",
    "- [http://overpass-api.de/query_form.html](http://overpass-api.de/query_form.html)\n",
    "\n",
    "Com a query:\n",
    "Latitude mínima: 40.6827 e máxima: 40.8808\n",
    "Longitude mínima: -74.0486 e máxima: -73.9043\n",
    "\n",
    "(\n",
    "node(40.6827000, -74.0486000, 40.8808000, -73.9043000);\n",
    "<;\n",
    ");out meta;\n",
    "\n",
    "Este mapa se refere ao quadrante referente a Manhanttan em New York City, e também areas ao redor devido ao quadrante.\n",
    "O motivo de eu ter pego este local e não minha cidade \"São Paulo\", pois é um lugar que gostei muito de visitar, e desejo retornar para umas férias mais longas, e até mesmo viver lá, o segundo motivo pela escolha é, que este dataset irá me auxiliar no enriquecimento de dados em outro projeto que estou trabalhando, para um projeto no MBA para análise de dados dos taxis de NYC.\n",
    "\n",
    "### Ambiente utilizado para desenvolvimento da análise:\n",
    "\n",
    "\n",
    "- Máquina: Macbook pro 2017 core I7 com 16GB de Ram, com sistema Operacional (macOS Hith Sierra 10.13.5 (17F77))\n",
    "\n",
    "- Anaconda, criei o environment py36\n",
    "- Python 3.6, jupyter, VS Code 1.25.1, pymongo 3.4.0\n",
    "- MongoDb no Docker: [https://hub.docker.com/r/library/mongo/](https://hub.docker.com/r/library/mongo/)\n",
    "\n",
    "#### Estrutura do projeto:\n",
    "\n",
    "\n",
    "-- amostra_arquivo.py (responsável por gerar o arquivo de amostra com k=10 e k=20)\n",
    "\n",
    "-- data_wrangling.py  (responsável por realizar a auditoria e limpeza de dados, assim como ler o XML (map_sample.osm) e gerar o json para ser importado no mongodb (map.osm.json)\n",
    "\n",
    "-- data_insert_in_mongodb.py (responsável por ler o json criado (map.osm.json) e inserir os dados no mongodb)\n",
    "\n",
    "-- data (diretório onde ficará os artefatos a serem processados e os logs)\n",
    "+ ------ map.osm (arquivo contendo o OSM da área do mapa que foi buscado no item (Mapa da Area a ser analisada))\n",
    "+ ------ map.osm-auditing.log (arquivo com logs de auditoria do processamento)\n",
    "+ ------ map.osm.json ( arquivo json que será inserido no mongodb)\n",
    "+ ------ map.osm.json-error-to-insert-json.log (arquivo de log com itens que tiveram erro no processamento ao inserir no mongoDB)\n",
    "\n",
    "Obs.1: Devido os artefatos serem muito grandes, estou disponibilizando o map.osm (map.osm.zip) e map.osm.json (map.osm.json.zip) no meu drive remoto (oneDrive):\n",
    "\n",
    "[https://1drv.ms/f/s!Au31I8svXayr6hS42acMhYrBXnzC](https://1drv.ms/f/s!Au31I8svXayr6hS42acMhYrBXnzC)\n",
    "\n",
    "Obs.2: Os arquivos de logs da auditoria com respostas das auditorias map.osm-auditing.log e do processamento do json para o mongoDB  map.osm.json-error-to-insert-json.log na pasta data\n",
    "\n",
    "Obs.: As querys foram executadas diretamente no mongoDB\n",
    "\n",
    "\n",
    "## \"Problems Encountered in the Map\" e Validações de dados e chaves para auditoria\n",
    "\n",
    "Após baixar o arquivo do mapa que irei utilizar, rodei o script amostra_arquivo.py com k = 10 para gerar um arquivo menor com amostragem dos dados de exemplo para iniciar o trabalho de análise, com isso pude ter uma visão geral dos tipos de chaves e tags do dataset.\n",
    "\n",
    "Os scripts de auditoria e limpeza dos dados está no arquivo data_wrangling.py, para análise de auditoria e processamento do arquivo json, que foi gerado para iniciar a analise de dados no mongodb, criei a função main:\n",
    "\n",
    "```python \n",
    "    def main(filename):\n",
    "      json_list = []\n",
    "\n",
    "      tags_auditing = {}\n",
    "      tag_k_auditing = {}\n",
    "      tag_k_v_yes_no_auditing = set()\n",
    "      postal_code = set()\n",
    "      street_address = {}\n",
    "      for event, element in ET.iterparse(filename):\n",
    "        street_address = audit_street_name(street_address, element)\n",
    "        postal_code = audit_postal_code(postal_code, element)\n",
    "        audit_count_tag_attribute_k_with_v_yes_no(tag_k_v_yes_no_auditing, element)\n",
    "        tag_k_auditing = audit_count_tag_attribute_k(tag_k_auditing, element)\n",
    "\n",
    "        if element.tag in MAIN_TAGS:\n",
    "          tags_auditing = audit_tags_subtags(tags_auditing, element)\n",
    "\n",
    "          json_list.append(process_json(element, tag_k_v_yes_no_auditing))\n",
    "\n",
    "      # You do not need to change this file\n",
    "      file_out = \"{0}.json\".format(filename)\n",
    "      with codecs.open(file_out, \"w\") as fo:\n",
    "        fo.write(json.dumps(json_list))\n",
    "```\n",
    "\n",
    "#### 1- Auditoria inicial de tags e atributos para avaliar consistências de dados\n",
    "\n",
    "Iniciei com a análise de contabilização de tags e chaves de atributos para verificar se existia algum desbalanceamento de estrutura para cada tag do xml e seus atributos, verifiquei que não existe inconsistências.\n",
    "\n",
    "\n",
    "\n",
    "#### 2- Auditoria de tags e subtags e seus atributos para avaliar consistências de dados\n",
    "\n",
    "Após a análise acima, conforme a documentação dos dados, as tags principais são node, relation e way, desta forma fiz uma análise das possíveis tags abaixo de cada\n",
    "\n",
    "\n",
    "Com base nesta análise foi possível identificar que para as tags principais pode-se ter as subtags:\n",
    "Node [ tag ] \n",
    "Relation [ member, tag ]\n",
    "Way [ nd, tag ]\n",
    "\n",
    "#### 3- Auditoria das chaves `\"k\"` das tags de subelementos ` \"tag\"` para avaliar consistência e ajustes do json gerado\n",
    "\n",
    "Com o fragmento de codigo abaixo iterando pelos elementos, do tipo 'tag', foi verificado a chave *k* e contando a quantidade de ocorrencias das chaves, e dessa forma será possível melhorar a estrutura e verificar os itens que deverão ter maior necessidade para auditar e limpar os dados:\n",
    "\n",
    "```Python\n",
    "def audit_count_tag_attribute_k(tag_k_auditing, element):\n",
    "  \n",
    "  if element.tag == 'tag':\n",
    "    v = 1\n",
    "    k = element.attrib['k']\n",
    "    if k in tag_k_auditing:\n",
    "      v = tag_k_auditing[k] + 1\n",
    "    tag_k_auditing[k] = v\n",
    "  return tag_k_auditing\n",
    "```\n",
    "\n",
    "Resposta:\n",
    "\n",
    "\n",
    "Problemas encontrados no mapeamento acima: \n",
    "- a chave k=\"Phone\" deverá ficar junto da tag do json phone do objeto\n",
    "- O o calor da chave 'addr:zip' deverá ser mapeado no mesma tag da chave 'addr:postcode'\n",
    "\n",
    "Conforme verificado na documentação do wiki, foi identificado alguns padrões de map features, sendo assim irei criar a tag primary_map_feature : {key : value, ...} para facilitar em categorização de possíveis tags, conforme mapeado acima.\n",
    "[https://wiki.openstreetmap.org/wiki/Map_Features](https://wiki.openstreetmap.org/wiki/Map_Features)\n",
    "\n",
    "Mapeado no código como uma lista:\n",
    "PRIMARY_FEATURES = [\n",
    "'aerialway','aeroway','amenity','barrier',\n",
    "'boundary','building','craft','emergency',\n",
    "'geological','highway','cycleway','busway',\n",
    "'sidewalk','historic','landuse','leisure',\n",
    "'man_made','military','natural','office',\n",
    "'place','power','line','public_transport',\n",
    "'railway','route','shop','sport',\n",
    "'tourism','waterway'\n",
    "]\n",
    "\n",
    "#### 4- Auditoria de tags e estruturação do json\n",
    "\n",
    "O mapeamento do json será definido conforme definicoes abaixo, para facilitar o mapeamento e análise:\n",
    "\n",
    "- Todas as chaves iniciadas com 'addr' serão mapeadas no json da chave 'address'\n",
    "- Todas as chaves iniciadas com 'building:*' serão agrupadas no json na chave 'building'\n",
    "- Todas as chaves iniciadas com 'cityracks.*' serão agrupadas no json na chave 'cityracks'\n",
    "- Todas as chaves iniciadas com 'crossing*' serão agrupadas no json na chave 'crossing'\n",
    "- Todas as chaves que iniciam com 'gnis:*' serão agrupadas no json na chave 'gnis'\n",
    "- A chave 'name' ficará na chave 'name', as demais chaves que iniciarem com 'name' ou 'old_name' irão ser agrupadas na chave do json 'names'\n",
    "- Todas as chaves iniciadas com 'tiger:*' serão agrupadas no json na chave 'tiger'\n",
    "- Todas as chaves que contenham o valor como `\"yes\"` / `\"no\"` deverão ser agrupadas na chave do json 'restrictions'\n",
    "- Todas as chaves que possuem a palavra `conditional` serão agrupadas na chave do json como 'restrictions'\n",
    "- As chaves 'opening_hours' serão consideradas como restrictions com o valor yes na chave principal\n",
    "\n",
    "\n",
    "#### 5- Auditoria de dados de tags com valores condicionais, e possíveis regras\n",
    "\n",
    "Após a auditoria de valores com yes / no como esperado as tags com keys condicionais que possuem divergências:\n",
    "\n",
    "'motor_vehicle:conditional': {'no @ (Mo-Fr 10:00-08:00; Sa,Su)',\n",
    "                               'no @ (Su 08:00-18:00)'},\n",
    "                               \n",
    "``` xml\n",
    " <tag k=\"access:conditional\" v=\"yes @ (axles=2 AND weight&lt;40 st); yes @ (axles=3 AND weight&lt;60 st); yes @ (axles=4 AND weight&lt;70 st); yes @ (axles&gt;=5 AND weight&lt;80 st)\"/>\n",
    "\n",
    " <tag k=\"motor_vehicle:conditional\" v=\"no @ (Mo-Fr 10:00-08:00; Sa,Su)\"/>\n",
    "\n",
    " <tag k=\"opening_hours\" v=\"Mo,Sa,Su,PH 09:00-17:00; Tu-Fr 08:00-20:00\"/>\n",
    " <tag k=\"opening_hours\" v=\"Mo-Fr 11:00-23:00; Sa,Su 10:00-23:00\"/>\n",
    " <tag k=\"opening_hours\" v=\"Mo-Fr 8:00-16:00, 17:00-23:00; Sa 9:00-16:00, 17:00-23:00; Su 9:00-17:00\"/>\n",
    "````\n",
    "                               \n",
    "As seguintes tags com keys possuem o valor com yes / no e possuem outros valores devido a isso no momento que for gerado o json ficarão dentro da chave 'restrictions':\n",
    "\n",
    "Obs.: Devido a chave de condicional poder possuir mais de uma condição conforme listado acima, no momento da limpeza dos dados irei realizar o seguinte ajuste no momento do condicional:\n",
    "\n",
    "- Modificar '`&lt;`' por ' < '\n",
    "- Modificar '`&gt;`' por ' > '\n",
    "- Fazer split pela string '); ' para separar as possiveis condicoes\n",
    "- Fazer split do valor por ' @ ' para separar o atributo inicial (yes / no / ...) do valor da condição\n",
    "- Caso o valor possuir mais de 1 caracter @\n",
    "entre outras regras\n",
    "\n",
    "Criado funções para normalizar os dados de condicionais, para retornar o dado de condicional conforme abaixo, gerado dados para testar algumas condições:\n",
    "\n",
    "```text\n",
    "\"yes @ (axles=2 AND weight&lt;40 st); yes @ (axles=3 AND weight&lt;60 st); yes @ (axles=4 AND weight&lt;70 st); yes @ (axles&gt;=5 AND weight&lt;80 st); no_left_turn @ (Mo-Fr 06:00-10:00,15:00-19:00); no_left_turn @ (Mo-Sa 07:00- 20:00); permissive @ (Mo-Fr 07:00-22:00; SH off);yes @ (Mo-Th 09:00-17:00; Fr 09:00-18:00; Sa 10:00-14:00)\"\n",
    "```\n",
    "\n",
    "\n",
    "```JSON\n",
    "{'no_left_turn': [{'friday': {'06:00-10:00', '15:00-19:00'},\n",
    "                   'monday': {'06:00-10:00', '15:00-19:00'},\n",
    "                   'thursday': {'06:00-10:00', '15:00-19:00'},\n",
    "                   'tuesday': {'06:00-10:00', '15:00-19:00'},\n",
    "                   'wednesday': {'06:00-10:00', '15:00-19:00'}},\n",
    "                  {'friday': {'07:00-20:00'},\n",
    "                   'monday': {'07:00-20:00'},\n",
    "                   'saturday': {'07:00-20:00'},\n",
    "                   'thursday': {'07:00-20:00'},\n",
    "                   'tuesday': {'07:00-20:00'},\n",
    "                   'wednesday': {'07:00-20:00'}}],\n",
    " 'permissive': [{' sh off': None,\n",
    "                 'friday': {'07:00-22:00'},\n",
    "                 'monday': {'07:00-22:00'},\n",
    "                 'thursday': {'07:00-22:00'},\n",
    "                 'tuesday': {'07:00-22:00'},\n",
    "                 'wednesday': {'07:00-22:00'}}],\n",
    " 'yes': [{'axles=2 and weight < 40 st': None},\n",
    "         {'axles=3 and weight < 60 st': None},\n",
    "         {'axles=4 and weight < 70 st': None},\n",
    "         {'axles >= 5 and weight < 80 st': None},\n",
    "         {'friday': {'09:00-18:00'},\n",
    "          'monday': {'09:00-17:00'},\n",
    "          'saturday': {'10:00-14:00'},\n",
    "          'thursday': {'09:00-17:00'},\n",
    "          'tuesday': {'09:00-17:00'},\n",
    "          'wednesday': {'09:00-17:00'}}]}\n",
    "```\n",
    "\n",
    "Verificado com o codigo:\n",
    "\n",
    "```python\n",
    "\n",
    "def audit_count_tag_attribute_k_with_v_yes_no(tag_k_v_yes_no_auditing, element):\n",
    "  if element.tag == 'tag':\n",
    "    v = element.attrib['v']\n",
    "    k = element.attrib['k']\n",
    "    if v == 'yes' or v == 'no' or v.startswith('yes ') or v.startswith('no ') or 'conditional' in k or k == 'opening_hours':\n",
    "      tag_k_v_yes_no_auditing.add(k)\n",
    "  return tag_k_v_yes_no_auditing\n",
    "\n",
    "```\n",
    "\n",
    "#### 6- Auditoria de sub-elementos e ajustes para normalização de dados\n",
    "\n",
    "##### 6.1- Normalização de zipcode (CEP)\n",
    "\n",
    "Conforme analisado os dados foram encontradas algumas inconsistências que serão ajustadas:\n",
    "\n",
    "1- Códigos de código postal com formato incorreto ou fora do range para new york, conforme a wikipedia o prefixo dos códigos postais de new york vão de 100 a 149 e o código postal deve conter 5 dígitos:\n",
    "\n",
    "[https://en.wikipedia.org/wiki/List_of_ZIP_code_prefixes] (https://en.wikipedia.org/wiki/List_of_ZIP_code_prefixes)\n",
    "\n",
    "Conforme o codigo de auditoria abaixo foi identificado alguns zipcodes com inconsistencia:\n",
    "\n",
    "```python\n",
    "def audit_postal_code(postal_code, element):\n",
    "  if element.tag == 'tag' and element.attrib['k'] in ['addr:zip', 'addr:postcode']:\n",
    "    if len(element.attrib['v']) != 5:\n",
    "      postal_code.add(element.attrib['v'])\n",
    "    else:\n",
    "      try:\n",
    "        v = int(element.attrib['v'])\n",
    "        if not (POSTAL_CODE_NY_RANGE[0] <= v <= POSTAL_CODE_NY_RANGE[1]):\n",
    "          postal_code.add(element.attrib['v'])\n",
    "      except ValueError: \n",
    "        postal_code.add(element.attrib['v'])\n",
    "    \n",
    "  return postal_code\n",
    "```\n",
    "\n",
    "Observações sobre as inconsistencias de zipcode possíveis processos de limpeza:\n",
    "\n",
    "- Os códigos com prefixo 070, 073, 076, etc ..., são de New Jersey proximo a New York, devido ao quadrante que foi pego como referencia, devido a isso não será alterado;\n",
    "- Os códigos com 4 dígitos após o '-' e os 5 dígitos, para resolver deverá ser utilizado apenas os primeiros 5 dígitos antes do '-'\n",
    "- O código postal 83 por exemplo, é referente ao Central Park, devido a isso não será alterado:\n",
    "```xml\n",
    "    <tag k=\"addr:housenumber\" v=\"34\" />\n",
    "    <tag k=\"addr:postcode\" v=\"83\" />\n",
    "    <tag k=\"addr:street\" v=\"Central Park North\" />\n",
    "```\n",
    "- Os códigos que possuem o prefixo NY ou o texto New York, NY , será removido e deixado apenas o zipcode.\n",
    "\n",
    "Para normalizar o zipcode foi utilizado o seguinte código:\n",
    "\n",
    "```python\n",
    "\n",
    "    def normalize_and_clean_zip_code(zipcode):\n",
    "      zip = zipcode.split()\n",
    "      for z in zip:\n",
    "        if z.isdigit() or len(z) == 10 or len(z) == 11 or (len(z) == 5 and z.isdigit()):\n",
    "          zipcode = z\n",
    "          break\n",
    "\n",
    "      return zipcode\n",
    "```\n",
    "\n",
    "##### 6.2- Normalização de Inconsistências em nomes de endereço:\n",
    "\n",
    "- Para identificar as inconsistencias em nomes de endereços foi realizado um split por espaços no nome do endereço e colocado o nome em uppercase, inserido e um dicionárioe contabilizado a quantidade de ocorrências para avaliar o impácto nos dados, e observado as ocorrencias diretamente no xml osm para garantir os dados, os principais erros encontrados foram em grandes abreviações em nomes de endereço, como exemplos abaixo:\n",
    "```xml\n",
    "    <tag k=\"addr:street\" v=\"W. 44th street\"/>\n",
    "    <tag k=\"addr:street\" v=\"E 55th St Ste. 301\"/>\n",
    "    <tag k=\"addr:street\" v=\"Prince st.\"/>\n",
    "```\n",
    "\n",
    "O código para avaliar o impacto e gerar o dicionário:\n",
    "\n",
    "```python\n",
    "def audit_street_name(street_address, element):\n",
    "  if element.tag == 'tag' and element.attrib['k'] == 'addr:street':\n",
    "    v = element.attrib['v'].upper().split(' ')\n",
    "    for valor in v:\n",
    "      count = 1\n",
    "      if valor in street_address:\n",
    "        count = street_address[valor] + 1\n",
    "      street_address[valor] = count\n",
    "  return street_address\n",
    "\n",
    "```\n",
    "\n",
    "Os principais casos de erro e abreviação no endereço, abaixo foram pegos os dados conforme análise dos logs:\n",
    "\n",
    "- Pontos Cardinais\n",
    "'WEST' : 21192 ,\n",
    "'W.' : 3 ,\n",
    "'W' : 20 ,\n",
    "\n",
    "'SOUTH' : 2056 ,\n",
    "'S' : 22 ,\n",
    "\n",
    "'NORTH' : 1369 ,\n",
    "'N' : 2 ,\n",
    "\n",
    "'EAST' : 18103 ,\n",
    "'E.' : 2 ,\n",
    "'E' : 17 ,\n",
    "\n",
    "- Tipos de Endreço:\n",
    "\n",
    "'ROAD' : 1701 ,\n",
    "'RD' : 1 ,\n",
    "\n",
    "'STREET' : 98465 ,\n",
    "\n",
    "'STREEET' : 1 ,\n",
    "'STEET' : 2 ,\n",
    "'ST.,' : 3 ,\n",
    "'ST.' : 21 ,\n",
    "'ST,' : 1 ,\n",
    "'ST' : 546 ,\n",
    "'STREER' : 1 ,\n",
    "\n",
    "'SUITE' : 6 ,\n",
    "'STE.' : 1 ,\n",
    "\n",
    "'PLACE' : 3786 ,\n",
    "'PL' : 1 ,\n",
    "\n",
    "'BOULEVARD' : 3286 ,\n",
    "\n",
    "'BLVD' : 8 ,\n",
    "'BLV.' : 1 ,\n",
    "\n",
    "'AVENUE' : 49407 ,\n",
    "\n",
    "'AVENUE;DEKALB' : 1 ,\n",
    "'AVENUE,#392' : 5 ,\n",
    "'AVENUE,' : 2 ,\n",
    "\n",
    "'AVENEU' : 1 ,\n",
    "'AVE.' : 1 ,\n",
    "'AVE,' : 2 ,\n",
    "'AVE' : 105 ,\n",
    "\n",
    "Tipos de endereço esperados:\n",
    "\n",
    "[\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "Obs.: caso o nome da rua inicie com St. deverá continuar como st e não ser alterado, como por exemplo.\n",
    "    \n",
    "    <tag k=\"addr:street\" v=\"St. Nicholas Aveneu\"/>\n",
    "    \n",
    "Obs.2: Alterações de pontos cardinais como East, North, West e South deverão ser alterados apenas quando a palavra a ser corrigida esteja no inicio do endereço. \n",
    "\n",
    "Para realizar as correções criei as variáveis abaixo com as informações de substituição.\n",
    "\n",
    "FIX_STREET_TYPE = { \n",
    "  \"RD\": \"ROAD\",\n",
    "  \"RD.\": \"ROAD\",\n",
    "  \"STREEET\" : \"STREET\",\n",
    "  \"STEET\" : \"STREET\",\n",
    "  \"ST.,\" : \"STREET\",\n",
    "  \"ST.\" : \"STREET\",\n",
    "  \"ST,\" : \"STREET\",\n",
    "  \"ST\" : \"STREET\",\n",
    "  \"STREER\" : \"STREET\",\n",
    "  \"STE\" : \"SUITE\",\n",
    "  \"STE.\" : \"SUITE\",\n",
    "  \"STE,\" : \"SUITE\",\n",
    "  \"PL\" : \"PLACE\",\n",
    "  \"BLVD\" : \"BOULEVARD\",\n",
    "  \"BLV.\" : \"BOULEVARD\",\n",
    "  \"BLV,\" : \"BOULEVARD\",\n",
    "  \"AVENUE,\" : \"AVENUE\",\n",
    "  \"AVENEU\" : \"AVENUE\",\n",
    "  \"AVE.\" : \"AVENUE\",\n",
    "  \"AVE,\" : \"AVENUE\",\n",
    "  \"AVE\" : \"AVENUE\",\n",
    "}\n",
    "\n",
    "FIX_CARDINAL_NAMES = {\n",
    "  'W.' : 'WEST',\n",
    "  'W'  : 'WEST',\n",
    "  'S'  : 'SOUTH',\n",
    "  'N'  : 'NORTH',\n",
    "  'E.' : 'EAST',\n",
    "  'E'  : 'EAST'\n",
    "}\n",
    "\n",
    "\n",
    "Para normalização do nome do endereço foi utilizado o seguinte códito:\n",
    "\n",
    "```python\n",
    "\n",
    "    def normalize_and_clean_street_name(street_address_name):\n",
    "      street_name_normalized = []\n",
    "      for i, s in enumerate(street_address_name.upper().split()):\n",
    "        s_new = s\n",
    "        if s not in EXPRECTED_STREET_TYPE:\n",
    "          if i > 0 and s in FIX_STREET_TYPE:\n",
    "            s_new = FIX_STREET_TYPE[s]\n",
    "\n",
    "        if s in FIX_CARDINAL_NAMES:\n",
    "          s_new = FIX_CARDINAL_NAMES[s]\n",
    "\n",
    "        street_name_normalized.append(s_new)\n",
    "      s = \" \".join(street_name_normalized)\n",
    "      pprint.pprint(s)\n",
    "\n",
    "      return s\n",
    "```\n",
    "##### 6.3- Normalização de Inconsistências em nomes da tag com a k=\"name\":\n",
    "\n",
    "- Nomes com `'`que podem quebrar o json no momento do processamento\n",
    "- Nomes com `/`\n",
    "- Nomes com `-`\n",
    "\n",
    "Correções em nomes para normalização:\n",
    "- Nomes que conterem os caracteres `\" ' | \\ / -` irei colocar um espaço em branco no local\n",
    "- Converter todos os nomes para uppercase\n",
    "\n",
    "\n",
    "\n",
    "```xml\n",
    "    <tag k=\"name\" v=\"McSorley's Old Ale House\" />\n",
    "\n",
    "    <tag k=\"name\" v=\"CVS/pharmacy\"/>\n",
    "\n",
    "    <tag k=\"name\" v=\"Rite-Aid\"/>\n",
    "```\n",
    "\n",
    "\n",
    "## Visão Geral dos Dados\n",
    "\n",
    "#### As estatísticas das informações gerais sobre o conjunto de dados foram computadas?\n",
    "\n",
    "Consultas de banco de dados são usados para fornecer uma visão estatística do conjunto de dados, como:\n",
    "\n",
    "###### Tamanho do arquivo\n",
    "\n",
    "### File sizes\n",
    "\n",
    "```\n",
    "map.osm ............... 372,5 MB\n",
    "map.osm.json .......... 423,1 MB\n",
    "\n",
    "Total de registros processados: ~ 1.6 M\n",
    "\n",
    "Estatistica do banco de dados (MongoDB):\n",
    "\n",
    "> show databases\n",
    "2ia                               0.000GB\n",
    "admin                             0.000GB\n",
    "config                            0.000GB\n",
    "local                             0.000GB\n",
    "test                              0.003GB\n",
    "udacity_datascience_for_business  0.138GB\n",
    "\n",
    "> show collections\n",
    "node\n",
    "\n",
    "> db.node.count()\n",
    "1605637\n",
    "\n",
    "```\n",
    "\n",
    "###### Número de usuários únicos\n",
    "\n",
    "```\n",
    "db.node.distinct( 'created.uid' ).length\n",
    "\n",
    "2707\n",
    "```\n",
    "\n",
    "###### Número de nós e caminhos\n",
    "\n",
    "``` code\n",
    "db.node.aggregate(\n",
    "   [\n",
    "      {\n",
    "        $group : {\n",
    "           _id : '$type',\n",
    "           count:  { $sum: 1 }\n",
    "        }\n",
    "      }\n",
    "   ]\n",
    ")\n",
    "\n",
    "{ \"_id\" : \"way\", \"count\" : 230055 }\n",
    "{ \"_id\" : \"node\", \"count\" : 1375582 }\n",
    "```\n",
    "\n",
    "###### Número de tipo de nós escolhidos Farmacias, Restaurantes e FastFoods.\n",
    "\n",
    "```\n",
    "db.node.aggregate(\n",
    "   [\n",
    "    { $match: { 'primary_map_feature.amenity' : { $in : ['pharmacy', 'restaurant', 'fast_food'] } } },\n",
    "      {\n",
    "        $group : {\n",
    "           _id : '$primary_map_feature.amenity',\n",
    "           count:  { $sum: 1 },\n",
    "        }\n",
    "      },\n",
    "      { $sort: { count : -1 } }\n",
    "   ]\n",
    ")\n",
    "\n",
    "{ \"_id\" : \"restaurant\", \"count\" : 2854 }\n",
    "{ \"_id\" : \"fast_food\", \"count\" : 672 }\n",
    "{ \"_id\" : \"pharmacy\", \"count\" : 295 }\n",
    "```\n",
    "\n",
    "###### Estatísticas adicionais que não estão na lista acima:\n",
    "\n",
    "- Top 10 restaurantes com mais lojas:\n",
    "\n",
    "```\n",
    "db.node.aggregate(\n",
    "   [\n",
    "    { $match: {\n",
    "       $and : [ {'primary_map_feature.amenity' : 'restaurant' } , {'name' : {$ne : null} }] } },\n",
    "      {\n",
    "        $group : {\n",
    "           _id : '$name',\n",
    "           count:  { $sum: 1 },\n",
    "        }\n",
    "      },\n",
    "      { $sort: { count : -1 } },\n",
    "      {$limit : 10}\n",
    "   ]\n",
    ")\n",
    "\n",
    "{ \"_id\" : \"BAREBURGER\", \"count\" : 13 }\n",
    "{ \"_id\" : \"CHIPOTLE\", \"count\" : 8 }\n",
    "{ \"_id\" : \"BLOCKHEADS\", \"count\" : 5 }\n",
    "{ \"_id\" : \"XI`AN FAMOUS FOODS\", \"count\" : 5 }\n",
    "{ \"_id\" : \"SPICE\", \"count\" : 5 }\n",
    "{ \"_id\" : \"SERAFINA\", \"count\" : 5 }\n",
    "{ \"_id\" : \"LE PAIN QUOTIDIEN\", \"count\" : 4 }\n",
    "{ \"_id\" : \"DALLAS BBQ\", \"count\" : 4 }\n",
    "{ \"_id\" : \"SWEETGREEN\", \"count\" : 4 }\n",
    "{ \"_id\" : \"BILL`S BAR & BURGER\", \"count\" : 4 }\n",
    "```\n",
    "\n",
    "\n",
    "- Top 10 fast foods com mais lojas:\n",
    "\n",
    "```\n",
    "db.node.aggregate(\n",
    "   [\n",
    "    { $match: {\n",
    "       $and : [ {'primary_map_feature.amenity' : 'fast_food' } , {'name' : {$ne : null} }] } },\n",
    "      {\n",
    "        $group : {\n",
    "           _id : '$name',\n",
    "           count:  { $sum: 1 },\n",
    "        }\n",
    "      },\n",
    "      { $sort: { count : -1 } },\n",
    "      {$limit : 10}\n",
    "   ]\n",
    "\n",
    ")\n",
    "\n",
    "{ \"_id\" : \"MCDONALD`S\", \"count\" : 70 }\n",
    "{ \"_id\" : \"SUBWAY\", \"count\" : 45 }\n",
    "{ \"_id\" : \"DUNKIN` DONUTS\", \"count\" : 20 }\n",
    "{ \"_id\" : \"CHIPOTLE\", \"count\" : 18 }\n",
    "{ \"_id\" : \"CHIPOTLE MEXICAN GRILL\", \"count\" : 12 }\n",
    "{ \"_id\" : \"TACO BELL\", \"count\" : 11 }\n",
    "{ \"_id\" : \"BURGER KING\", \"count\" : 9 }\n",
    "{ \"_id\" : \"FIVE GUYS\", \"count\" : 9 }\n",
    "{ \"_id\" : \"DUNKIN DONUTS\", \"count\" : 9 }\n",
    "{ \"_id\" : \"SHAKE SHACK\", \"count\" : 9 }\n",
    "```\n",
    "\n",
    "- Top 10 farmacias com mais lojas:\n",
    "\n",
    "```\n",
    "db.node.aggregate(\n",
    "   [\n",
    "    { $match: {\n",
    "       $and : [ {'primary_map_feature.amenity' : 'pharmacy' } , {'name' : {$ne : null} }] } },\n",
    "      {\n",
    "        $group : {\n",
    "           _id : '$name',\n",
    "           count:  { $sum: 1 },\n",
    "        }\n",
    "      },\n",
    "      { $sort: { count : -1 } },\n",
    "      {$limit : 10}\n",
    "   ]\n",
    ")\n",
    "\n",
    "{ \"_id\" : \"DUANE READE\", \"count\" : 89 }\n",
    "{ \"_id\" : \"RITE AID\", \"count\" : 36 }\n",
    "{ \"_id\" : \"CVS\", \"count\" : 24 }\n",
    "{ \"_id\" : \"CVS PHARMACY\", \"count\" : 18 }\n",
    "{ \"_id\" : \"WALGREENS\", \"count\" : 9 }\n",
    "{ \"_id\" : \"DUANE READE PHARMACY\", \"count\" : 2 }\n",
    "{ \"_id\" : \"RITE AIDE\", \"count\" : 2 }\n",
    "{ \"_id\" : \"DUANEREADE\", \"count\" : 2 }\n",
    "{ \"_id\" : \"CITY CHEMIST\", \"count\" : 2 }\n",
    "{ \"_id\" : \"STEINWAY STREET PHARMACY\", \"count\" : 1 }\n",
    "```\n",
    "\n",
    "- Top 10 farmacias com mais lojas que tem funcionamento nos domingos:\n",
    "\n",
    "``` code\n",
    "db.node.aggregate(\n",
    "   [\n",
    "    { $match: {\n",
    "       $and : [{'restrictions_rules.opening_hours.yes' : {$exists : 'sunday'}},  {'primary_map_feature.amenity' : pharmacy' } , {'name' : {$ne : null} }] } },\n",
    "      {\n",
    "        $group : {\n",
    "           _id : '$name',\n",
    "           count:  { $sum: 1 },\n",
    "        }\n",
    "      },\n",
    "      { $sort: { count : -1 } },\n",
    "      {$limit : 10}\n",
    "   ]\n",
    "\n",
    ")\n",
    "\n",
    "{ \"_id\" : \"DUANE READE\", \"count\" : 50 }\n",
    "{ \"_id\" : \"RITE AID\", \"count\" : 21 }\n",
    "{ \"_id\" : \"CVS PHARMACY\", \"count\" : 15 }\n",
    "{ \"_id\" : \"CVS\", \"count\" : 7 }\n",
    "{ \"_id\" : \"WALGREENS\", \"count\" : 3 }\n",
    "{ \"_id\" : \"DUANE READE PHARMACY\", \"count\" : 2 }\n",
    "{ \"_id\" : \"GST PHARMACY\", \"count\" : 1 }\n",
    "{ \"_id\" : \"VERNON BLVD PHARMACY\", \"count\" : 1 }\n",
    "{ \"_id\" : \"92 PHARMACY INC.\", \"count\" : 1 }\n",
    "{ \"_id\" : \"CHELSEA ROYAL CARE PHARMACY\", \"count\" : 1 }\n",
    "```\n",
    "\n",
    "## Outras Ideias sobre os Dados\n",
    "\n",
    "- Uma ideia adicional seria os orgão do governo ou ler de outros datasets publicos auxiliarem no enriquecimento dos dados, até mesmo os próprios estabelecimentos enviarem dados.\n",
    "\n",
    "Por Exemplo, utilizando os dados de farmacia:\n",
    "\n",
    "    No total de 295 farmacias apenas 94,23% possuem nome registrado e apenas 61,69% possuem nome do estabelecimento e endereço registrados.\n",
    "    \n",
    "```\n",
    "> db.node.find({'primary_map_feature.amenity' : 'pharmacy'}).length()\n",
    "295\n",
    "\n",
    "> db.node.find( {$and : [ {'primary_map_feature.amenity' : 'pharmacy'}, {name : { $ne : null} } ]}).length()\n",
    "\n",
    "278\n",
    "\n",
    "> db.node.find( {$and : [ {'primary_map_feature.amenity' : 'pharmacy'}, {name : { $ne : null} }, { address: { $exists: true } } ]}).length()\n",
    "\n",
    "182\n",
    "```\n",
    "\n",
    "Sendo assim, para ter uma base mais consisa teria que ter muito mais divulgação e auxilio de todas as comunidades para melhorar os dados e consistencia destes dados, pois não adianta ter uma base tão grande se não for atualizada.\n",
    "\n",
    "\n",
    "# Conclusão\n",
    "\n",
    "Este mapa se refere ao quadrante referente a Manhanttan em New York City, e também às areas ao redor devido ao quadrante escolhido. Como conclusão do trabalho ficou entendido que os dados estudados foram muito bons para o entendimento, prática e o aprendizado na limpeza dos dados e estruturação de objetos, assim como melhorar sua análise. Aqui vale uma observação para esta conclusão: segundo os dados utilizados, a massa de dados é bem grande, porém existem inconsistencias e ajustes a serem feitos.\n",
    "É interessante notar que alguns problemas foram encontrados durante a fase de análise dos dados e que os dados obtidos refere-se ao translado de usuários que frequentemente utilizaram o Taxi como meio de transporte.\n",
    "\n",
    "-- Solução: Auditoria de tags e estruturação do json\n",
    "-  Benefício: Limpeza dos dados para chaves inválidas\n",
    "\n",
    "-- Solução: Auditoria de sub-elementos e ajustes para normalização de dados\n",
    "Benefícios\n",
    "\n",
    "-  Benefício 1: Normalização dos zipcode (CEP)\n",
    "-  Benefício 2: Normalização de Inconsistências em nomes de endereço\n",
    "-  Benefício 3: Normalização de Inconsistências em nomes de Tags \n",
    "\n",
    "-- Problemas esperados\n",
    "- Problema 1: Normalização do zipcode\n",
    "- Problema 2: Normalização do nome do endereço\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
